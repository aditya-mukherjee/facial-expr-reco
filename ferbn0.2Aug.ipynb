{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, concatenate, Flatten, AveragePooling2D\n",
    "from keras.layers import*\n",
    "from keras.models import Model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import*\n",
    "from keras.regularizers import l2\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_epoch = 40\n",
    "def poly_decay(epoch):\n",
    "    base_lr = 0.01\n",
    "    lr = base_lr*((1-(epoch/max_epoch))**0.5)\n",
    "    return lr\n",
    "lrate = LearningRateScheduler(poly_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen =  ImageDataGenerator(rotation_range=5, width_shift_range=0.08, shear_range=0.1,\n",
    "                               height_shift_range=0.1, zoom_range=0.1)\n",
    "val_datagen =  ImageDataGenerator(rotation_range=5, width_shift_range=0.08, shear_range=0.1,\n",
    "                               height_shift_range=0.1, zoom_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train = \"fer2013/train/\"\n",
    "path_val = \"fer2013/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 287100 images belonging to 7 classes.\n",
      "Found 35890 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        path_train,\n",
    "        target_size=(40, 40),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        color_mode = 'grayscale')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        path_val,\n",
    "        target_size=(40, 40),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        color_mode = 'grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  if sys.path[0] == '':\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  del sys.path[0]\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  \n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  app.launch_new_instance()\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(208, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4096, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(7, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_input (InputLayer)          (None, 40, 40, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 20, 20, 64)   3200        img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 5, 192)    110784      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 192)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 3, 3, 192)    768         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 96)     165984      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 16)     76816       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 192)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 64)     12352       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 128)    110720      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 32)     12832       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 32)     6176        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 256)    0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 3, 3, 256)    1024        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 3, 3, 128)    295040      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 3, 3, 32)     204832      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 128)    32896       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 3, 3, 192)    221376      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 3, 3, 96)     76896       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 3, 3, 64)     16448       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 480)    0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 480)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2, 2, 480)    1920        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 2, 2, 96)     414816      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 2, 16)     192016      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 2, 2, 480)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 2, 2, 192)    92352       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 2, 2, 208)    179920      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 2, 2, 48)     19248       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 2, 2, 64)     30784       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2, 2, 512)    0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2, 2, 512)    2048        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         2101248     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         4195328     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            7175        dense_2[0][0]                    \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 8,584,999\n",
      "Trainable params: 8,582,119\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(40,40,1), name='img_input')\n",
    "x = Conv2D(64,7, strides=(2,2), activation = 'relu',padding='same')(img_input)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2,2),padding='same')(x)   \n",
    "x = Conv2D(192,3,strides=(2,2),padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2,2),padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "\n",
    "#first inception layer 3a\n",
    "x1 = Conv2D(64,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #1*1\n",
    "x2 = Conv2D(96,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #3*3 reduce\n",
    "x2 = Conv2D(128,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x2) #3*3 \n",
    "x3 = Conv2D(16,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #5*5 reduce\n",
    "x3 = Conv2D(32,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x3) #5*5 \n",
    "x4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(x) #pool proj\n",
    "x4 = Conv2D(32,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x4) #1*1\n",
    "x = concatenate([x1,x2,x3,x4], axis = 3)\n",
    "x = BatchNormalization()(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#second inception layer 3b\n",
    "x1 = Conv2D(128,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #1*1\n",
    "x2 = Conv2D(128,3,padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #3*3 reduce\n",
    "x2 = Conv2D(192,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x2) #3*3 \n",
    "x3 = Conv2D(32,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #5*5 reduce\n",
    "x3 = Conv2D(96,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x3) #5*5 \n",
    "x4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(x) #pool proj\n",
    "x4 = Conv2D(64,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x4)\n",
    "x = concatenate([x1,x2,x3,x4], axis = 3)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2,2),padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#third inception layer 4a\n",
    "x1 = Conv2D(192,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #1*1\n",
    "x2 = Conv2D(96,3,padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #3*3 reduce\n",
    "x2 = Conv2D(208,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x2) #3*3 \n",
    "x3 = Conv2D(16,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #5*5 reduce\n",
    "x3 = Conv2D(48,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x3) #5*5 \n",
    "x4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(x) #pool proj\n",
    "x4 = Conv2D(64,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x4) #1*1\n",
    "x = concatenate([x1,x2,x3,x4], axis = 3)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(4096, activation='relu', W_regularizer=l2(0.0002))(x)\n",
    "x = Dense(1024, activation='relu', W_regularizer=l2(0.0002))(x)\n",
    "x = Dense(7, activation='softmax', W_regularizer=l2(0.0002))(x)\n",
    "final_model = Model(inputs = [img_input], outputs = [x])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, nesterov=False)\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.load_weights(\"weights/aug-batchnorm-0.2dropout-01-0.3436.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "4486/4485 [==============================] - 1967s 438ms/step - loss: 1.5674 - acc: 0.3507 - val_loss: 1.6234 - val_acc: 0.3364\n",
      "\n",
      "Epoch 00001: saving model to weights/aug-batchnorm-0.2dropout-01-0.3364.hdf5\n",
      "\n",
      "Epoch 00001: saving model to weights/aug-batchnorm-0.2dropout-01-0.3364.hdf5\n",
      "\n",
      "Epoch 00001: saving model to weights/aug-batchnorm-0.2dropout-01-0.3364.hdf5\n",
      "Epoch 2/40\n",
      "4486/4485 [==============================] - 1955s 436ms/step - loss: 1.4690 - acc: 0.4147 - val_loss: 1.3993 - val_acc: 0.4506\n",
      "\n",
      "Epoch 00002: saving model to weights/aug-batchnorm-0.2dropout-02-0.4506.hdf5\n",
      "\n",
      "Epoch 00002: saving model to weights/aug-batchnorm-0.2dropout-02-0.4506.hdf5\n",
      "\n",
      "Epoch 00002: saving model to weights/aug-batchnorm-0.2dropout-02-0.4506.hdf5\n",
      "Epoch 3/40\n",
      "4486/4485 [==============================] - 1925s 429ms/step - loss: 1.3700 - acc: 0.4618 - val_loss: 1.5037 - val_acc: 0.4155\n",
      "\n",
      "Epoch 00003: saving model to weights/aug-batchnorm-0.2dropout-03-0.4155.hdf5\n",
      "\n",
      "Epoch 00003: saving model to weights/aug-batchnorm-0.2dropout-03-0.4155.hdf5\n",
      "\n",
      "Epoch 00003: saving model to weights/aug-batchnorm-0.2dropout-03-0.4155.hdf5\n",
      "Epoch 4/40\n",
      "4486/4485 [==============================] - 1989s 443ms/step - loss: 1.2943 - acc: 0.5033 - val_loss: 1.3804 - val_acc: 0.4756\n",
      "\n",
      "Epoch 00004: saving model to weights/aug-batchnorm-0.2dropout-04-0.4756.hdf5\n",
      "\n",
      "Epoch 00004: saving model to weights/aug-batchnorm-0.2dropout-04-0.4756.hdf5\n",
      "\n",
      "Epoch 00004: saving model to weights/aug-batchnorm-0.2dropout-04-0.4756.hdf5\n",
      "Epoch 5/40\n",
      "4486/4485 [==============================] - 2084s 464ms/step - loss: 1.2469 - acc: 0.5265 - val_loss: 1.3402 - val_acc: 0.4937\n",
      "\n",
      "Epoch 00005: saving model to weights/aug-batchnorm-0.2dropout-05-0.4937.hdf5\n",
      "\n",
      "Epoch 00005: saving model to weights/aug-batchnorm-0.2dropout-05-0.4937.hdf5\n",
      "\n",
      "Epoch 00005: saving model to weights/aug-batchnorm-0.2dropout-05-0.4937.hdf5\n",
      "Epoch 6/40\n",
      "4486/4485 [==============================] - 2064s 460ms/step - loss: 1.2110 - acc: 0.5459 - val_loss: 1.3148 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00006: saving model to weights/aug-batchnorm-0.2dropout-06-0.5033.hdf5\n",
      "\n",
      "Epoch 00006: saving model to weights/aug-batchnorm-0.2dropout-06-0.5033.hdf5\n",
      "\n",
      "Epoch 00006: saving model to weights/aug-batchnorm-0.2dropout-06-0.5033.hdf5\n",
      "Epoch 7/40\n",
      "4486/4485 [==============================] - 2084s 464ms/step - loss: 1.1720 - acc: 0.5630 - val_loss: 1.2894 - val_acc: 0.5190\n",
      "\n",
      "Epoch 00007: saving model to weights/aug-batchnorm-0.2dropout-07-0.5190.hdf5\n",
      "\n",
      "Epoch 00007: saving model to weights/aug-batchnorm-0.2dropout-07-0.5190.hdf5\n",
      "\n",
      "Epoch 00007: saving model to weights/aug-batchnorm-0.2dropout-07-0.5190.hdf5\n",
      "Epoch 8/40\n",
      "4486/4485 [==============================] - 2182s 486ms/step - loss: 1.1396 - acc: 0.5779 - val_loss: 1.2443 - val_acc: 0.5340\n",
      "\n",
      "Epoch 00008: saving model to weights/aug-batchnorm-0.2dropout-08-0.5340.hdf5\n",
      "\n",
      "Epoch 00008: saving model to weights/aug-batchnorm-0.2dropout-08-0.5340.hdf5\n",
      "\n",
      "Epoch 00008: saving model to weights/aug-batchnorm-0.2dropout-08-0.5340.hdf5\n",
      "Epoch 9/40\n",
      "4486/4485 [==============================] - 2165s 483ms/step - loss: 1.1129 - acc: 0.5897 - val_loss: 1.2905 - val_acc: 0.5143\n",
      "\n",
      "Epoch 00009: saving model to weights/aug-batchnorm-0.2dropout-09-0.5143.hdf5\n",
      "\n",
      "Epoch 00009: saving model to weights/aug-batchnorm-0.2dropout-09-0.5143.hdf5\n",
      "\n",
      "Epoch 00009: saving model to weights/aug-batchnorm-0.2dropout-09-0.5143.hdf5\n",
      "Epoch 10/40\n",
      "4486/4485 [==============================] - 2129s 475ms/step - loss: 1.0883 - acc: 0.6001 - val_loss: 1.2694 - val_acc: 0.5268\n",
      "\n",
      "Epoch 00010: saving model to weights/aug-batchnorm-0.2dropout-10-0.5268.hdf5\n",
      "\n",
      "Epoch 00010: saving model to weights/aug-batchnorm-0.2dropout-10-0.5268.hdf5\n",
      "\n",
      "Epoch 00010: saving model to weights/aug-batchnorm-0.2dropout-10-0.5268.hdf5\n",
      "Epoch 11/40\n",
      "4486/4485 [==============================] - 2098s 468ms/step - loss: 1.0624 - acc: 0.6111 - val_loss: 1.3330 - val_acc: 0.5086\n",
      "\n",
      "Epoch 00011: saving model to weights/aug-batchnorm-0.2dropout-11-0.5086.hdf5\n",
      "\n",
      "Epoch 00011: saving model to weights/aug-batchnorm-0.2dropout-11-0.5086.hdf5\n",
      "\n",
      "Epoch 00011: saving model to weights/aug-batchnorm-0.2dropout-11-0.5086.hdf5\n",
      "Epoch 12/40\n",
      "4486/4485 [==============================] - 2097s 467ms/step - loss: 1.0406 - acc: 0.6210 - val_loss: 1.2660 - val_acc: 0.5360\n",
      "\n",
      "Epoch 00012: saving model to weights/aug-batchnorm-0.2dropout-12-0.5360.hdf5\n",
      "\n",
      "Epoch 00012: saving model to weights/aug-batchnorm-0.2dropout-12-0.5360.hdf5\n",
      "\n",
      "Epoch 00012: saving model to weights/aug-batchnorm-0.2dropout-12-0.5360.hdf5\n",
      "Epoch 13/40\n",
      "4486/4485 [==============================] - 2094s 467ms/step - loss: 1.0167 - acc: 0.6306 - val_loss: 1.2717 - val_acc: 0.5328\n",
      "\n",
      "Epoch 00013: saving model to weights/aug-batchnorm-0.2dropout-13-0.5328.hdf5\n",
      "\n",
      "Epoch 00013: saving model to weights/aug-batchnorm-0.2dropout-13-0.5328.hdf5\n",
      "\n",
      "Epoch 00013: saving model to weights/aug-batchnorm-0.2dropout-13-0.5328.hdf5\n",
      "Epoch 14/40\n",
      "4486/4485 [==============================] - 2098s 468ms/step - loss: 0.9927 - acc: 0.6415 - val_loss: 1.2484 - val_acc: 0.5537\n",
      "\n",
      "Epoch 00014: saving model to weights/aug-batchnorm-0.2dropout-14-0.5537.hdf5\n",
      "\n",
      "Epoch 00014: saving model to weights/aug-batchnorm-0.2dropout-14-0.5537.hdf5\n",
      "\n",
      "Epoch 00014: saving model to weights/aug-batchnorm-0.2dropout-14-0.5537.hdf5\n",
      "Epoch 15/40\n",
      "4486/4485 [==============================] - 2101s 468ms/step - loss: 0.9719 - acc: 0.6504 - val_loss: 1.2749 - val_acc: 0.5439\n",
      "\n",
      "Epoch 00015: saving model to weights/aug-batchnorm-0.2dropout-15-0.5439.hdf5\n",
      "\n",
      "Epoch 00015: saving model to weights/aug-batchnorm-0.2dropout-15-0.5439.hdf5\n",
      "\n",
      "Epoch 00015: saving model to weights/aug-batchnorm-0.2dropout-15-0.5439.hdf5\n",
      "Epoch 16/40\n",
      "4486/4485 [==============================] - 2089s 466ms/step - loss: 0.9512 - acc: 0.6610 - val_loss: 1.2184 - val_acc: 0.5688\n",
      "\n",
      "Epoch 00016: saving model to weights/aug-batchnorm-0.2dropout-16-0.5688.hdf5\n",
      "\n",
      "Epoch 00016: saving model to weights/aug-batchnorm-0.2dropout-16-0.5688.hdf5\n",
      "\n",
      "Epoch 00016: saving model to weights/aug-batchnorm-0.2dropout-16-0.5688.hdf5\n",
      "Epoch 17/40\n",
      "4486/4485 [==============================] - 2092s 466ms/step - loss: 0.9295 - acc: 0.6702 - val_loss: 1.2241 - val_acc: 0.5706\n",
      "\n",
      "Epoch 00017: saving model to weights/aug-batchnorm-0.2dropout-17-0.5706.hdf5\n",
      "\n",
      "Epoch 00017: saving model to weights/aug-batchnorm-0.2dropout-17-0.5706.hdf5\n",
      "\n",
      "Epoch 00017: saving model to weights/aug-batchnorm-0.2dropout-17-0.5706.hdf5\n",
      "Epoch 18/40\n",
      "4486/4485 [==============================] - 2095s 467ms/step - loss: 0.9073 - acc: 0.6811 - val_loss: 1.2720 - val_acc: 0.5634\n",
      "\n",
      "Epoch 00018: saving model to weights/aug-batchnorm-0.2dropout-18-0.5634.hdf5\n",
      "\n",
      "Epoch 00018: saving model to weights/aug-batchnorm-0.2dropout-18-0.5634.hdf5\n",
      "\n",
      "Epoch 00018: saving model to weights/aug-batchnorm-0.2dropout-18-0.5634.hdf5\n",
      "Epoch 19/40\n",
      "4486/4485 [==============================] - 2093s 467ms/step - loss: 0.8876 - acc: 0.6904 - val_loss: 1.3969 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00019: saving model to weights/aug-batchnorm-0.2dropout-19-0.5094.hdf5\n",
      "\n",
      "Epoch 00019: saving model to weights/aug-batchnorm-0.2dropout-19-0.5094.hdf5\n",
      "\n",
      "Epoch 00019: saving model to weights/aug-batchnorm-0.2dropout-19-0.5094.hdf5\n",
      "Epoch 20/40\n",
      "4486/4485 [==============================] - 2090s 466ms/step - loss: 0.8688 - acc: 0.6984 - val_loss: 1.2586 - val_acc: 0.5619\n",
      "\n",
      "Epoch 00020: saving model to weights/aug-batchnorm-0.2dropout-20-0.5619.hdf5\n",
      "\n",
      "Epoch 00020: saving model to weights/aug-batchnorm-0.2dropout-20-0.5619.hdf5\n",
      "\n",
      "Epoch 00020: saving model to weights/aug-batchnorm-0.2dropout-20-0.5619.hdf5\n",
      "Epoch 21/40\n",
      "4486/4485 [==============================] - 2094s 467ms/step - loss: 0.8498 - acc: 0.7076 - val_loss: 1.2930 - val_acc: 0.5652\n",
      "\n",
      "Epoch 00021: saving model to weights/aug-batchnorm-0.2dropout-21-0.5652.hdf5\n",
      "\n",
      "Epoch 00021: saving model to weights/aug-batchnorm-0.2dropout-21-0.5652.hdf5\n",
      "\n",
      "Epoch 00021: saving model to weights/aug-batchnorm-0.2dropout-21-0.5652.hdf5\n",
      "Epoch 22/40\n",
      "4486/4485 [==============================] - 2101s 468ms/step - loss: 0.8289 - acc: 0.7166 - val_loss: 1.3496 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00022: saving model to weights/aug-batchnorm-0.2dropout-22-0.5553.hdf5\n",
      "\n",
      "Epoch 00022: saving model to weights/aug-batchnorm-0.2dropout-22-0.5553.hdf5\n",
      "\n",
      "Epoch 00022: saving model to weights/aug-batchnorm-0.2dropout-22-0.5553.hdf5\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4486/4485 [==============================] - 2080s 464ms/step - loss: 0.8120 - acc: 0.7239 - val_loss: 1.3247 - val_acc: 0.5589\n",
      "\n",
      "Epoch 00023: saving model to weights/aug-batchnorm-0.2dropout-23-0.5589.hdf5\n",
      "\n",
      "Epoch 00023: saving model to weights/aug-batchnorm-0.2dropout-23-0.5589.hdf5\n",
      "\n",
      "Epoch 00023: saving model to weights/aug-batchnorm-0.2dropout-23-0.5589.hdf5\n",
      "Epoch 24/40\n",
      "4486/4485 [==============================] - 2083s 464ms/step - loss: 0.7956 - acc: 0.7319 - val_loss: 1.2991 - val_acc: 0.5775\n",
      "\n",
      "Epoch 00024: saving model to weights/aug-batchnorm-0.2dropout-24-0.5775.hdf5\n",
      "\n",
      "Epoch 00024: saving model to weights/aug-batchnorm-0.2dropout-24-0.5775.hdf5\n",
      "\n",
      "Epoch 00024: saving model to weights/aug-batchnorm-0.2dropout-24-0.5775.hdf5\n",
      "Epoch 25/40\n",
      "4486/4485 [==============================] - 2084s 465ms/step - loss: 0.7747 - acc: 0.7406 - val_loss: 1.3508 - val_acc: 0.5596\n",
      "\n",
      "Epoch 00025: saving model to weights/aug-batchnorm-0.2dropout-25-0.5596.hdf5\n",
      "\n",
      "Epoch 00025: saving model to weights/aug-batchnorm-0.2dropout-25-0.5596.hdf5\n",
      "\n",
      "Epoch 00025: saving model to weights/aug-batchnorm-0.2dropout-25-0.5596.hdf5\n",
      "Epoch 26/40\n",
      "4486/4485 [==============================] - 2090s 466ms/step - loss: 0.7578 - acc: 0.7498 - val_loss: 1.3461 - val_acc: 0.5692\n",
      "\n",
      "Epoch 00026: saving model to weights/aug-batchnorm-0.2dropout-26-0.5692.hdf5\n",
      "\n",
      "Epoch 00026: saving model to weights/aug-batchnorm-0.2dropout-26-0.5692.hdf5\n",
      "\n",
      "Epoch 00026: saving model to weights/aug-batchnorm-0.2dropout-26-0.5692.hdf5\n",
      "Epoch 27/40\n",
      "4486/4485 [==============================] - 2093s 467ms/step - loss: 0.7419 - acc: 0.7559 - val_loss: 1.3674 - val_acc: 0.5630\n",
      "\n",
      "Epoch 00027: saving model to weights/aug-batchnorm-0.2dropout-27-0.5630.hdf5\n",
      "\n",
      "Epoch 00027: saving model to weights/aug-batchnorm-0.2dropout-27-0.5630.hdf5\n",
      "\n",
      "Epoch 00027: saving model to weights/aug-batchnorm-0.2dropout-27-0.5630.hdf5\n",
      "Epoch 28/40\n",
      "4486/4485 [==============================] - 2084s 465ms/step - loss: 0.7245 - acc: 0.7646 - val_loss: 1.3784 - val_acc: 0.5651\n",
      "\n",
      "Epoch 00028: saving model to weights/aug-batchnorm-0.2dropout-28-0.5651.hdf5\n",
      "\n",
      "Epoch 00028: saving model to weights/aug-batchnorm-0.2dropout-28-0.5651.hdf5\n",
      "\n",
      "Epoch 00028: saving model to weights/aug-batchnorm-0.2dropout-28-0.5651.hdf5\n",
      "Epoch 29/40\n",
      "4486/4485 [==============================] - 2090s 466ms/step - loss: 0.7032 - acc: 0.7733 - val_loss: 1.3760 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00029: saving model to weights/aug-batchnorm-0.2dropout-29-0.5653.hdf5\n",
      "\n",
      "Epoch 00029: saving model to weights/aug-batchnorm-0.2dropout-29-0.5653.hdf5\n",
      "\n",
      "Epoch 00029: saving model to weights/aug-batchnorm-0.2dropout-29-0.5653.hdf5\n",
      "Epoch 30/40\n",
      "4486/4485 [==============================] - 2091s 466ms/step - loss: 0.6868 - acc: 0.7803 - val_loss: 1.4216 - val_acc: 0.5728\n",
      "\n",
      "Epoch 00030: saving model to weights/aug-batchnorm-0.2dropout-30-0.5728.hdf5\n",
      "\n",
      "Epoch 00030: saving model to weights/aug-batchnorm-0.2dropout-30-0.5728.hdf5\n",
      "\n",
      "Epoch 00030: saving model to weights/aug-batchnorm-0.2dropout-30-0.5728.hdf5\n",
      "Epoch 31/40\n",
      "4486/4485 [==============================] - 2090s 466ms/step - loss: 0.6733 - acc: 0.7863 - val_loss: 1.4041 - val_acc: 0.5727\n",
      "\n",
      "Epoch 00031: saving model to weights/aug-batchnorm-0.2dropout-31-0.5727.hdf5\n",
      "\n",
      "Epoch 00031: saving model to weights/aug-batchnorm-0.2dropout-31-0.5727.hdf5\n",
      "\n",
      "Epoch 00031: saving model to weights/aug-batchnorm-0.2dropout-31-0.5727.hdf5\n",
      "Epoch 32/40\n",
      "4486/4485 [==============================] - 2088s 466ms/step - loss: 0.6561 - acc: 0.7945 - val_loss: 1.4034 - val_acc: 0.5819\n",
      "\n",
      "Epoch 00032: saving model to weights/aug-batchnorm-0.2dropout-32-0.5819.hdf5\n",
      "\n",
      "Epoch 00032: saving model to weights/aug-batchnorm-0.2dropout-32-0.5819.hdf5\n",
      "\n",
      "Epoch 00032: saving model to weights/aug-batchnorm-0.2dropout-32-0.5819.hdf5\n",
      "Epoch 33/40\n",
      "4486/4485 [==============================] - 2092s 466ms/step - loss: 0.6368 - acc: 0.8020 - val_loss: 1.4434 - val_acc: 0.5736\n",
      "\n",
      "Epoch 00033: saving model to weights/aug-batchnorm-0.2dropout-33-0.5736.hdf5\n",
      "\n",
      "Epoch 00033: saving model to weights/aug-batchnorm-0.2dropout-33-0.5736.hdf5\n",
      "\n",
      "Epoch 00033: saving model to weights/aug-batchnorm-0.2dropout-33-0.5736.hdf5\n",
      "Epoch 34/40\n",
      "4486/4485 [==============================] - 2093s 466ms/step - loss: 0.6193 - acc: 0.8094 - val_loss: 1.4343 - val_acc: 0.5790\n",
      "\n",
      "Epoch 00034: saving model to weights/aug-batchnorm-0.2dropout-34-0.5790.hdf5\n",
      "\n",
      "Epoch 00034: saving model to weights/aug-batchnorm-0.2dropout-34-0.5790.hdf5\n",
      "\n",
      "Epoch 00034: saving model to weights/aug-batchnorm-0.2dropout-34-0.5790.hdf5\n",
      "Epoch 35/40\n",
      "4486/4485 [==============================] - 2091s 466ms/step - loss: 0.6007 - acc: 0.8161 - val_loss: 1.4565 - val_acc: 0.5694\n",
      "\n",
      "Epoch 00035: saving model to weights/aug-batchnorm-0.2dropout-35-0.5694.hdf5\n",
      "\n",
      "Epoch 00035: saving model to weights/aug-batchnorm-0.2dropout-35-0.5694.hdf5\n",
      "\n",
      "Epoch 00035: saving model to weights/aug-batchnorm-0.2dropout-35-0.5694.hdf5\n",
      "Epoch 36/40\n",
      "4486/4485 [==============================] - 2101s 468ms/step - loss: 0.5838 - acc: 0.8228 - val_loss: 1.4476 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00036: saving model to weights/aug-batchnorm-0.2dropout-36-0.5768.hdf5\n",
      "\n",
      "Epoch 00036: saving model to weights/aug-batchnorm-0.2dropout-36-0.5768.hdf5\n",
      "\n",
      "Epoch 00036: saving model to weights/aug-batchnorm-0.2dropout-36-0.5768.hdf5\n",
      "Epoch 37/40\n",
      "2706/4485 [=================>............] - ETA: 13:17 - loss: 0.5609 - acc: 0.8317"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4f607589b9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                          callbacks = callbacks_list)\n\u001b[0m",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath= \"weights/\" +\"aug-batchnorm-0.2dropout\" + \"-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list.append(checkpoint)\n",
    "model_history = final_model.fit_generator(train_generator, train_generator.samples/train_generator.batch_size,\n",
    "        validation_data = validation_generator, epochs = max_epoch,\n",
    "        validation_steps = validation_generator.samples/validation_generator.batch_size,\n",
    "                                         callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " 145/4485 [..............................] - ETA: 31:30 - loss: 1.9118 - acc: 0.2407"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4f607589b9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                          callbacks = callbacks_list)\n\u001b[0m",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amitoj/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig(\"bn0.2.jpg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
