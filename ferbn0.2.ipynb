{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, concatenate, Flatten, AveragePooling2D\n",
    "from keras.layers import*\n",
    "from keras.models import Model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import*\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_epoch = 20\n",
    "def poly_decay(epoch):\n",
    "    base_lr = 0.01\n",
    "    lr = base_lr*((1-(epoch/max_epoch))**0.5)\n",
    "    return lr\n",
    "lrate = LearningRateScheduler(poly_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = np.load(\"Xtrain.npy\")\n",
    "Xtest = np.load(\"Xtest.npy\")\n",
    "Xval = np.load(\"Xval.npy\")\n",
    "Ytrain = np.load(\"Ytrain.npy\")\n",
    "Ytest = np.load(\"Ytest.npy\")\n",
    "Yval = np.load(\"Yval.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  if sys.path[0] == '':\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  del sys.path[0]\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  \n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  app.launch_new_instance()\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(208, 3, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, 5, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 1, padding=\"same\", activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4096, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "/home/amitoj/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(7, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_input (InputLayer)          (None, 40, 40, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 20, 20, 64)   3200        img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 5, 192)    110784      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 192)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 3, 3, 192)    768         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 96)     165984      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 16)     76816       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 192)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 64)     12352       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 128)    110720      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 32)     12832       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 32)     6176        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 256)    0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 3, 3, 256)    1024        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 3, 3, 128)    295040      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 3, 3, 32)     204832      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 128)    32896       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 3, 3, 192)    221376      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 3, 3, 96)     76896       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 3, 3, 64)     16448       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 480)    0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 480)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2, 2, 480)    1920        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 2, 2, 96)     414816      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 2, 16)     192016      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 2, 2, 480)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 2, 2, 192)    92352       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 2, 2, 208)    179920      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 2, 2, 48)     19248       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 2, 2, 64)     30784       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2, 2, 512)    0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2, 2, 512)    2048        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         2101248     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         4195328     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            7175        dense_2[0][0]                    \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 8,584,999\n",
      "Trainable params: 8,582,119\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(40,40,1), name='img_input')\n",
    "x = Conv2D(64,7, strides=(2,2), activation = 'relu',padding='same')(img_input)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2,2),padding='same')(x)   \n",
    "x = Conv2D(192,3,strides=(2,2),padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2,2),padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#first inception layer 3a\n",
    "x1 = Conv2D(64,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #1*1\n",
    "x2 = Conv2D(96,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #3*3 reduce\n",
    "x2 = Conv2D(128,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x2) #3*3 \n",
    "x3 = Conv2D(16,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #5*5 reduce\n",
    "x3 = Conv2D(32,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x3) #5*5 \n",
    "x4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(x) #pool proj\n",
    "x4 = Conv2D(32,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x4) #1*1\n",
    "x = concatenate([x1,x2,x3,x4], axis = 3)\n",
    "x = BatchNormalization()(x)\n",
    "#second inception layer 3b\n",
    "x1 = Conv2D(128,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #1*1\n",
    "x2 = Conv2D(128,3,padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #3*3 reduce\n",
    "x2 = Conv2D(192,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x2) #3*3 \n",
    "x3 = Conv2D(32,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #5*5 reduce\n",
    "x3 = Conv2D(96,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x3) #5*5 \n",
    "x4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(x) #pool proj\n",
    "x4 = Conv2D(64,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x4)\n",
    "x = concatenate([x1,x2,x3,x4], axis = 3)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2,2),padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "#third inception layer 4a\n",
    "x1 = Conv2D(192,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #1*1\n",
    "x2 = Conv2D(96,3,padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #3*3 reduce\n",
    "x2 = Conv2D(208,3, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x2) #3*3 \n",
    "x3 = Conv2D(16,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x) #5*5 reduce\n",
    "x3 = Conv2D(48,5, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x3) #5*5 \n",
    "x4 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(x) #pool proj\n",
    "x4 = Conv2D(64,1, padding='same', activation = 'relu', W_regularizer=l2(0.0002))(x4) #1*1\n",
    "x = concatenate([x1,x2,x3,x4], axis = 3)\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(4096, activation='relu', W_regularizer=l2(0.0002))(x)\n",
    "x = Dense(1024, activation='relu', W_regularizer=l2(0.0002))(x)\n",
    "x = Dense(7, activation='softmax', W_regularizer=l2(0.0002))(x)\n",
    "final_model = Model(inputs = [img_input], outputs = [x])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, nesterov=False)\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 287100 samples, validate on 35890 samples\n",
      "Epoch 1/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 2.4050 - acc: 0.3965\n",
      "Epoch 00001: val_acc improved from -inf to 0.42859, saving model to weights/batchnorm-0.2dropout-01-0.4286.hdf5\n",
      "287100/287100 [==============================] - 1881s 7ms/step - loss: 2.4049 - acc: 0.3965 - val_loss: 2.3657 - val_acc: 0.4286\n",
      "Epoch 2/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 2.1217 - acc: 0.5096\n",
      "Epoch 00002: val_acc did not improve\n",
      "287100/287100 [==============================] - 1927s 7ms/step - loss: 2.1217 - acc: 0.5096 - val_loss: 2.3022 - val_acc: 0.4246\n",
      "Epoch 3/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.9863 - acc: 0.5542\n",
      "Epoch 00003: val_acc improved from 0.42859 to 0.49069, saving model to weights/batchnorm-0.2dropout-03-0.4907.hdf5\n",
      "287100/287100 [==============================] - 1828s 6ms/step - loss: 1.9863 - acc: 0.5542 - val_loss: 2.2684 - val_acc: 0.4907\n",
      "Epoch 4/20\n",
      "287040/287100 [============================>.] - ETA: 1s - loss: 1.8834 - acc: 0.5848\n",
      "Epoch 00004: val_acc improved from 0.49069 to 0.52265, saving model to weights/batchnorm-0.2dropout-04-0.5227.hdf5\n",
      "287100/287100 [==============================] - 5458s 19ms/step - loss: 1.8834 - acc: 0.5848 - val_loss: 2.0327 - val_acc: 0.5227\n",
      "Epoch 5/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.7964 - acc: 0.6096\n",
      "Epoch 00005: val_acc did not improve\n",
      "287100/287100 [==============================] - 1863s 6ms/step - loss: 1.7964 - acc: 0.6096 - val_loss: 2.3075 - val_acc: 0.4370\n",
      "Epoch 6/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.7146 - acc: 0.6336\n",
      "Epoch 00006: val_acc improved from 0.52265 to 0.54040, saving model to weights/batchnorm-0.2dropout-06-0.5404.hdf5\n",
      "287100/287100 [==============================] - 1867s 7ms/step - loss: 1.7146 - acc: 0.6336 - val_loss: 1.9834 - val_acc: 0.5404\n",
      "Epoch 7/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.6369 - acc: 0.6561\n",
      "Epoch 00007: val_acc improved from 0.54040 to 0.54140, saving model to weights/batchnorm-0.2dropout-07-0.5414.hdf5\n",
      "287100/287100 [==============================] - 1902s 7ms/step - loss: 1.6368 - acc: 0.6562 - val_loss: 1.9919 - val_acc: 0.5414\n",
      "Epoch 8/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.5614 - acc: 0.6787\n",
      "Epoch 00008: val_acc improved from 0.54140 to 0.55057, saving model to weights/batchnorm-0.2dropout-08-0.5506.hdf5\n",
      "287100/287100 [==============================] - 1890s 7ms/step - loss: 1.5614 - acc: 0.6787 - val_loss: 1.9719 - val_acc: 0.5506\n",
      "Epoch 9/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.4906 - acc: 0.6984\n",
      "Epoch 00009: val_acc did not improve\n",
      "287100/287100 [==============================] - 1908s 7ms/step - loss: 1.4905 - acc: 0.6984 - val_loss: 2.0335 - val_acc: 0.5234\n",
      "Epoch 10/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.4229 - acc: 0.7195\n",
      "Epoch 00010: val_acc did not improve\n",
      "287100/287100 [==============================] - 1909s 7ms/step - loss: 1.4228 - acc: 0.7195 - val_loss: 2.0277 - val_acc: 0.5480\n",
      "Epoch 11/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.3582 - acc: 0.7389\n",
      "Epoch 00011: val_acc did not improve\n",
      "287100/287100 [==============================] - 1910s 7ms/step - loss: 1.3583 - acc: 0.7389 - val_loss: 2.1513 - val_acc: 0.5181\n",
      "Epoch 12/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.2933 - acc: 0.7587\n",
      "Epoch 00012: val_acc did not improve\n",
      "287100/287100 [==============================] - 1886s 7ms/step - loss: 1.2933 - acc: 0.7587 - val_loss: 2.2368 - val_acc: 0.4854\n",
      "Epoch 13/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.2358 - acc: 0.7766\n",
      "Epoch 00013: val_acc improved from 0.55057 to 0.55277, saving model to weights/batchnorm-0.2dropout-13-0.5528.hdf5\n",
      "287100/287100 [==============================] - 1873s 7ms/step - loss: 1.2358 - acc: 0.7766 - val_loss: 2.0692 - val_acc: 0.5528\n",
      "Epoch 14/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.1771 - acc: 0.7957\n",
      "Epoch 00014: val_acc improved from 0.55277 to 0.56328, saving model to weights/batchnorm-0.2dropout-14-0.5633.hdf5\n",
      "287100/287100 [==============================] - 1902s 7ms/step - loss: 1.1772 - acc: 0.7957 - val_loss: 2.0830 - val_acc: 0.5633\n",
      "Epoch 15/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.1283 - acc: 0.8100\n",
      "Epoch 00015: val_acc did not improve\n",
      "287100/287100 [==============================] - 1877s 7ms/step - loss: 1.1283 - acc: 0.8101 - val_loss: 2.1616 - val_acc: 0.5459\n",
      "Epoch 16/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.0797 - acc: 0.8255\n",
      "Epoch 00016: val_acc did not improve\n",
      "287100/287100 [==============================] - 1877s 7ms/step - loss: 1.0797 - acc: 0.8255 - val_loss: 2.1903 - val_acc: 0.5550\n",
      "Epoch 17/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 1.0321 - acc: 0.8411\n",
      "Epoch 00017: val_acc improved from 0.56328 to 0.56854, saving model to weights/batchnorm-0.2dropout-17-0.5685.hdf5\n",
      "287100/287100 [==============================] - 1884s 7ms/step - loss: 1.0321 - acc: 0.8411 - val_loss: 2.1612 - val_acc: 0.5685\n",
      "Epoch 18/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 0.9891 - acc: 0.8549\n",
      "Epoch 00018: val_acc did not improve\n",
      "287100/287100 [==============================] - 1874s 7ms/step - loss: 0.9891 - acc: 0.8549 - val_loss: 2.3307 - val_acc: 0.5553\n",
      "Epoch 19/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 0.9524 - acc: 0.8654\n",
      "Epoch 00019: val_acc did not improve\n",
      "287100/287100 [==============================] - 1902s 7ms/step - loss: 0.9524 - acc: 0.8654 - val_loss: 2.3242 - val_acc: 0.5556\n",
      "Epoch 20/20\n",
      "287040/287100 [============================>.] - ETA: 0s - loss: 0.9169 - acc: 0.8762\n",
      "Epoch 00020: val_acc did not improve\n",
      "287100/287100 [==============================] - 1903s 7ms/step - loss: 0.9169 - acc: 0.8762 - val_loss: 2.3054 - val_acc: 0.5645\n"
     ]
    }
   ],
   "source": [
    "filepath= \"weights/\" +\"batchnorm-0.2dropout\" + \"-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list.append(checkpoint)\n",
    "model_history = final_model.fit(Xtrain, Ytrain, epochs = max_epoch, batch_size = 64,callbacks = callbacks_list ,\n",
    "                                validation_data=(Xval, Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEte/Eze1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc73db2ce90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig(\"bn0.2.jpg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
